
# Arrays in Bash

When I am working on large data sets my mind often drifts back to an old Simpsons episode. Bart is in France and being taught to pick grapes. They show him a detailed technique and he does it successfully. Then they say "Very Good. Now do it a million times!"


<p align="center">
<img src="../img/simpsons.png" width="400">
</p>
<p align = "center">
We've all been here
</p>

A pipeline or process may seem easy or fast when you have 1-3 samples but totally daunting when you have 50. When scaling up you need to consider file overwriting, computational resources, and time.

One easy way to scale up is to use the array feature of slurm

## What is the array feature?

